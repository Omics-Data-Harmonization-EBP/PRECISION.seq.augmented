fourth_store <- c(fourth_store, the_fourth)
}
probabilities <- sum(num_vote_obtained > fourth_store) / simulations
return(probabilities)
}
# Calculate the probabilities
probabilities <- calculate_probabilities(total_judges = 50, votes_per_judge = 3, total_participants = 20, simulations = 10000, num_vote_obtained = 50)
# Function to simulate one round of voting
simulate_voting <- function(total_judges, votes_per_judge, total_participants) {
votes <- rep(0, total_participants)
for (j in 1:total_judges) {
# Each judge gives votes to 3 different participants
participants <- sample(total_participants, votes_per_judge, replace = FALSE)
for (p in participants) {
votes[p] <- votes[p] + 1
}
}
return(votes)
}
fourth_store <- c()
for (s in 1:simulations) {
votes <- simulate_voting(total_judges, votes_per_judge, total_participants)
the_fourth <- sort(votes, decreasing = TRUE)[4]
fourth_store <- c(fourth_store, the_fourth)
}
simulations
sum(fourth_store >= 50) / simulations
sum(50 >= fourth_store) / simulations
sum(10 >= fourth_store) / simulations
sum(4 >= fourth_store) / simulations
sum(5 >= fourth_store) / simulations
sum(6 >= fourth_store) / simulations
sum(8 >= fourth_store) / simulations
sum(9 >= fourth_store) / simulations
sum(10 >= fourth_store) / simulations
?sample
sample(20, 3)
sample(20, 3, replace = T)
sample(20, 3, replace = F)
set.seed(123)  # Set a seed for reproducibility
total_judges <- 50
votes_per_judge <- 3
total_participants <- 20
simulations <- 10000  # Number of simulations to perform
# Function to simulate one round of voting
simulate_voting <- function(total_judges, votes_per_judge, total_participants) {
votes <- rep(0, total_participants)
for (j in 1:total_judges) {
# Each judge gives votes to 3 different participants
participants <- sample(total_participants, votes_per_judge, replace = FALSE)
for (p in participants) {
votes[p] <- votes[p] + 1
}
}
return(votes)
}
fourth_store <- c()
for (s in 1:100000) {
votes <- simulate_voting(total_judges = 50, votes_per_judge = 3, total_participants = 20)
the_fourth <- sort(votes, decreasing = TRUE)[4]
fourth_store <- c(fourth_store, the_fourth)
}
sum(10 >= fourth_store) / 100000
sum(9 >= fourth_store) / 100000
sum(50 >= fourth_store) / 100000
sum(40 >= fourth_store) / 100000
sum(20 >= fourth_store) / 100000
sum(7 >= fourth_store) / 100000
sum(9 >= fourth_store) / 100000
sum(8 >= fourth_store) / 100000
sum(10 >= fourth_store) / 100000
sum(11 >= fourth_store) / 100000
library(PRECISION.seq.augmented)
library(PRECISION.seq.augmented)
?methods::setClass
library(PRECISION.seq.augmented)
library(PRECISION.seq.augmented)
library(sva)
?sva
library(bladderbatch)
BiocManager::install("bladderbatch")
BiocManager::install("bladderbatch")
install.packages("C:/Users/jianz/Downloads/bladderbatch_1.40.0.tar.gz")
library(bladderbatch)
data(bladderdata)
dat <- bladderEset[1:5000,]
pheno = pData(dat)
edata = exprs(dat)
mod = model.matrix(~as.factor(cancer), data=pheno)
mod0 = model.matrix(~1,data=pheno)
n.sv = num.sv(edata,mod,method="leek")
svobj = sva(edata,mod,mod0,n.sv=n.sv)
n.sv
svobj$sv
?fsva
dim(edata)
library(PRECISION.seq.augmented)
library(PRECISION.seq.augmented)
library(PRECISION.seq.augmented)
c(5:9, 13:19)
library(PRECISION.seq.augmented)
library(PRECISION.seq.augmented)
load("C:/Users/jianz/SynologyDrive/Ongoing_Project/Methodology/202105_precision.seq.clustering/20240121_v5A/data/database/processed/01_empirical_simulation.RData")
raw_benchmark_list[[1]]
data = raw_benchmark_list[[1]]$data
group = raw_benchmark_list[[1]]$label
mu1 <- c
mu2 <- 1.8 * c
sigma <- 1
n <- ncol(data)
m <- nrow(data)
mu1 <- c
mu2 <- 1.8 * c
sigma <- 1
n <- ncol(data)
m <- nrow(data)
groups = group
unique_groups <- unique(groups)
groups
unique_groups
group = "MXF"
indices <- which(groups == group)
size <- length(indices)
num_same_batch <- round(size * jaccard_index)
jaccard_inex  = 0.5
jaccard_index  = 0.5
num_same_batch <- round(size * jaccard_index)
batch <- sample(c("Batch1", "Batch2"), 1)
other_batch <- if (batch == "Batch1") "Batch2" else "Batch1"
batch_assignments[indices] <- c(rep(batch, num_same_batch), rep(other_batch, size - num_same_batch))
batch_assignments <- vector("character", n)
batch_assignments[indices] <- c(rep(batch, num_same_batch), rep(other_batch, size - num_same_batch))
batch_assignments[indices] <- sample(batch_assignments[indices])
batch_assignments
jaccard <- function(a, b) {
intersection = length(intersect(a, b))
union = length(a) + length(b) - intersection
return (intersection/union)
}
batch_assignments <- vector("character", n)
unique_groups <- unique(groups)
for (group in unique_groups) {
indices <- which(groups == group)
size <- length(indices)
num_same_batch <- round(size * jaccard_index)
batch <- sample(c("Batch1", "Batch2"), 1)
other_batch <- if (batch == "Batch1") "Batch2" else "Batch1"
batch_assignments[indices] <- c(rep(batch, num_same_batch), rep(other_batch, size - num_same_batch))
batch_assignments[indices] <- sample(batch_assignments[indices])
}
batch_assignments
jaccard(batch_assignments, groups)
jaccard_index
jaccard(as.numeric(as.factor(batch_assignments)), as.numeric(as.factor(groups)))
as.numeric(as.factor(batch_assignments))
jaccard(as.numeric(as.factor(batch_assignments))-1, as.numeric(as.factor(groups))-1)
batch_assignments <- vector("character", n)
unique_groups <- unique(groups)
for (group in unique_groups) {
indices <- which(groups == group)
size <- length(indices)
num_same_batch <- round(size * jaccard_index)
batch <- group
other_batch <- if (batch == "Batch1") "Batch2" else "Batch1"
batch_assignments[indices] <- c(rep(batch, num_same_batch), rep(other_batch, size - num_same_batch))
batch_assignments[indices] <- sample(batch_assignments[indices])
}
jaccard(as.numeric(as.factor(batch_assignments))-1, as.numeric(as.factor(groups))-1)
batch_assignments
jaccard(as.numeric(as.factor(batch_assignments))-1[1:27], as.numeric(as.factor(groups))-1[1:27])
if (is.null(jaccard_index) || jaccard_index < 0 || jaccard_index > 1) {
stop("Please provide a valid Jaccard index between 0 and 1 for partial correlation.")
}
unique_groups <- unique(groups)
for (group in unique_groups) {
indices <- which(groups == group)
size <- length(indices)
num_same_batch <- round(size * jaccard_index)
batch <- sample(c("Batch1", "Batch2"), 1)
other_batch <- if (batch == "Batch1") "Batch2" else "Batch1"
batch_assignments[indices] <- c(rep(batch, num_same_batch), rep(other_batch, size - num_same_batch))
batch_assignments[indices] <- sample(batch_assignments[indices])
}
batch_assignments
jaccard(as.numeric(as.factor(batch_assignments))-1[1:27], as.numeric(as.factor(groups))-1[1:27])
jaccard_index = 0.8
unique_groups <- unique(groups)
for (group in unique_groups) {
indices <- which(groups == group)
size <- length(indices)
num_same_batch <- round(size * jaccard_index)
batch <- sample(c("Batch1", "Batch2"), 1)
other_batch <- if (batch == "Batch1") "Batch2" else "Batch1"
batch_assignments[indices] <- c(rep(batch, num_same_batch), rep(other_batch, size - num_same_batch))
batch_assignments[indices] <- sample(batch_assignments[indices])
}
batch_assignments
jaccard()
jaccard(as.numeric(as.factor(batch_assignments))-1[1:27], as.numeric(as.factor(groups))-1[1:27])
jaccard(batch_assignments, groups)
groups
table(batch_assignments, groups)
44/54
jaccard_index = 0.5
batch_assignments <- vector("character", n)
unique_groups <- unique(groups)
for (group in unique_groups) {
indices <- which(groups == group)
size <- length(indices)
num_same_batch <- round(size * jaccard_index)
batch <- sample(c("Batch1", "Batch2"), 1)
other_batch <- if (batch == "Batch1") "Batch2" else "Batch1"
batch_assignments[indices] <- c(rep(batch, num_same_batch), rep(other_batch, size - num_same_batch))
batch_assignments[indices] <- sample(batch_assignments[indices])
}
table(batch_assignments, groups)
jaccard_index = 1
batch_assignments <- vector("character", n)
unique_groups <- unique(groups)
for (group in unique_groups) {
indices <- which(groups == group)
size <- length(indices)
num_same_batch <- round(size * jaccard_index)
batch <- sample(c("Batch1", "Batch2"), 1)
other_batch <- if (batch == "Batch1") "Batch2" else "Batch1"
batch_assignments[indices] <- c(rep(batch, num_same_batch), rep(other_batch, size - num_same_batch))
batch_assignments[indices] <- sample(batch_assignments[indices])
}
batch_assignments
table(batch_assignments, groups)
levels(unique_groups)
unique_groups
which(group == unique_groups)
batch_assignments <- vector("character", n)
jaccard_index
unique_groups <- unique(groups)
for (group in unique_groups) {
indices <- which(groups == group)
size <- length(indices)
num_same_batch <- round(size * jaccard_index)
batch <- c("Batch1", "Batch2")[which(group == unique_groups)]
other_batch <- if (batch == "Batch1") "Batch2" else "Batch1"
batch_assignments[indices] <- c(rep(batch, num_same_batch), rep(other_batch, size - num_same_batch))
batch_assignments[indices] <- sample(batch_assignments[indices])
}
batch_assignments
jaccard_index == 0
jaccard_index = 0
batch_assignments <- vector("character", n)
unique_groups <- unique(groups)
for (group in unique_groups) {
indices <- which(groups == group)
size <- length(indices)
num_same_batch <- round(size * jaccard_index)
batch <- c("Batch1", "Batch2")[which(group == unique_groups)]
other_batch <- if (batch == "Batch1") "Batch2" else "Batch1"
batch_assignments[indices] <- c(rep(batch, num_same_batch), rep(other_batch, size - num_same_batch))
batch_assignments[indices] <- sample(batch_assignments[indices])
}
batch_assignments
unique_groups <- unique(groups)
batch_assignments <- rep(c("Batch1", "Batch2"), length = length(groups))[seq_along(unique_groups)]
batch_assignments <- batch_assignments[as.character(groups)]
batch_assignments
unique_groups <- unique(groups)
batch_assignments <- rep(c("Batch1", "Batch2"), length = length(groups))[seq_along(unique_groups)]
batch_assignments
batch_assignments <- rep(c("Batch1", "Batch2"), length = length(groups))[seq_along(unique_groups)]
rep(c("Batch1", "Batch2"), length = length(groups))[seq_along(unique_groups)]
rep(c("Batch1", "Batch2"), length = length(groups))
seq_along(unique_groups)
partial_index
partial_index = 1
batch_assignments <- vector("character", n)
unique_groups <- unique(groups)
for (group in unique_groups) {
indices <- which(groups == group)
size <- length(indices)
num_batch1 <- round(size * partial_index)
num_batch2 <- size - num_batch1
if (group == unique_groups[1]) {
batch_assignments[indices] <- c(rep("Batch1", num_batch1), rep("Batch2", num_batch2))
} else if (group == unique_groups[2]) {
batch_assignments[indices] <- c(rep("Batch2", num_batch1), rep("Batch1", num_batch2))
}
batch_assignments[indices] <- sample(batch_assignments[indices])
}
batch_assignments
partial_index = 0.5
batch_assignments <- vector("character", n)
unique_groups <- unique(groups)
for (group in unique_groups) {
indices <- which(groups == group)
size <- length(indices)
num_batch1 <- round(size * partial_index)
num_batch2 <- size - num_batch1
if (group == unique_groups[1]) {
batch_assignments[indices] <- c(rep("Batch1", num_batch1), rep("Batch2", num_batch2))
} else if (group == unique_groups[2]) {
batch_assignments[indices] <- c(rep("Batch2", num_batch1), rep("Batch1", num_batch2))
}
batch_assignments[indices] <- sample(batch_assignments[indices])
}
batch_assignments
table(batch_assignments, groups)
partial_index = 0.7
batch_assignments <- vector("character", n)
unique_groups <- unique(groups)
for (group in unique_groups) {
indices <- which(groups == group)
size <- length(indices)
num_batch1 <- round(size * partial_index)
num_batch2 <- size - num_batch1
if (group == unique_groups[1]) {
batch_assignments[indices] <- c(rep("Batch1", num_batch1), rep("Batch2", num_batch2))
} else if (group == unique_groups[2]) {
batch_assignments[indices] <- c(rep("Batch2", num_batch1), rep("Batch1", num_batch2))
}
batch_assignments[indices] <- sample(batch_assignments[indices])
}
table(batch_assignments, groups)
38/54
seq_along(unique_groups)
groups
batch_assignments <- groups
batch_assignments
library(PRECISION.seq.augmented)
library(PRECISION.seq.augmented)
library(PRECISION.seq.augmented)
?sva::ComBat_seq
?knn
?handling.effects
>handling.effects()
?handling.effects()
?handling.effects
load("C:/Users/jianz/Downloads/precision.data.RData")
data.benchmark
data.miR.info
data.group
save(data.benchmark, data.miR.info, data.group, data.test, file = "raw.data.RData")
library(PRECISION.seq.augmented)
data.benchmark
library(PRECISION.seq.augmented)
# Step 0: Prepare the 'precision' object
example_cluster <- create.precision.cluster(data = data.test, label = data.group)
example_cluster
# Step 1: Harmonize via TMM method
harmonized_data <- harmon.TMM(example_cluster)
library(tidyverse)
# Step 1: Harmonize via TMM method
harmonized_data <- harmon.TMM(example_cluster)
library(PRECISION.seq.augmented)
# Step 1: Harmonize via TMM method
harmonized_data <- harmon.TMM(example_cluster)
?calcNormFactors
??calcNormFactors
edgeR::calcNormFactors()
library(PRECISION.seq.augmented)
library(tidyverse)
library(PRECISION.seq.augmented)
library(tidyverse)
## Overview
The PRECISION.seq.augmented package provides a comprehensive framework for clustering analysis of sequencing data through a two-stage pipeline:
1. **Data Harmonization**: The first crucial step involves harmonizing the sequencing data to ensure consistency and compatibility across different samples. In this package,
2. **Clustering Analysis**: Following data harmonization, one can perform clustering analysis using the following clustering methods:
# Step 0: Prepare the 'precision' object
example_cluster <- create.precision.cluster(data = data.test, label = data.group)
# Step 1: Harmonize via TMM method
harmonized_data <- harmon.TMM(example_cluster)
library(edgeR)
# Step 1: Harmonize via TMM method
harmonized_data <- harmon.TMM(example_cluster)
# Step 2: Clustering via K-means
example_cluster <- cluster.kmeans(example_cluster, k = 2)
example_cluster
# Step 0: Prepare the 'precision' object
example_cluster <- create.precision.cluster(data = data.test, label = data.group)
# Step 1: Harmonize via TMM method
example_cluster <- harmon.TMM(example_cluster)
# Step 2: Clustering via K-means
example_cluster <- cluster.kmeans(example_cluster, k = 2)
example_cluster
example_cluster@harmon.train.data
example_cluster@cluster.result
library(PRECISION.seq.augmented)
library(tidyverse)
library(edgeR)
harmon.all <- function(object){
object@harmon.train.data$Raw$dat.harmonized <- object@raw.train.data$data
object <- harmon.TC(object)
object <- harmon.UQ(object)
object <- harmon.med(object)
object <- harmon.TMM(object)
object <- harmon.DESeq(object)
object <- harmon.PoissonSeq(object)
object <- harmon.QN(object)
object <- harmon.RUVg(object)
object <- harmon.RUVs(object)
object <- harmon.RUVr(object)
return(object)
}
cluster.all <- function(object){
object <- cluster.kmeans(object)
object <- cluster.hc(object)
object <- cluster.som(object)
object <- cluster.mnm(object)
object <- cluster.pam.euclidean(object)
object <- cluster.pam.pearson(object)
object <- cluster.pam.spearman(object)
return(object)
}
# Step 0: Prepare the 'precision' object
example_cluster <- create.precision.cluster(data = data.test, label = data.group)
# Step 1: Harmonize via all the methods
example_cluster <- harmon.all(example_cluster)
library(EDASeq)
library(PRECISION.seq.augmented)
library(tidyverse)
library(edgeR)
library(EDASeq)
harmon.all <- function(object){
object@harmon.train.data$Raw$dat.harmonized <- object@raw.train.data$data
object <- harmon.TC(object)
object <- harmon.UQ(object)
object <- harmon.med(object)
object <- harmon.TMM(object)
object <- harmon.DESeq(object)
object <- harmon.PoissonSeq(object)
object <- harmon.QN(object)
object <- harmon.RUVg(object)
object <- harmon.RUVs(object)
object <- harmon.RUVr(object)
return(object)
}
cluster.all <- function(object){
object <- cluster.kmeans(object)
object <- cluster.hc(object)
object <- cluster.som(object)
object <- cluster.mnm(object)
object <- cluster.pam.euclidean(object)
object <- cluster.pam.pearson(object)
object <- cluster.pam.spearman(object)
return(object)
}
# Step 2: Clustering via all the methods
example_cluster <- cluster.all(example_cluster)
# Step 0: Prepare the 'precision' object
example_cluster <- create.precision.cluster(data = data.test, label = data.group)
# Step 1: Harmonize via all the methods
example_cluster <- harmon.all(example_cluster)
library(PRECISION.seq.augmented)
library(tidyverse)
library(edgeR)
library(EDASeq)
library(RUVSeq)
harmon.all <- function(object){
object@harmon.train.data$Raw$dat.harmonized <- object@raw.train.data$data
object <- harmon.TC(object)
object <- harmon.UQ(object)
object <- harmon.med(object)
object <- harmon.TMM(object)
object <- harmon.DESeq(object)
object <- harmon.PoissonSeq(object)
object <- harmon.QN(object)
object <- harmon.RUVg(object)
object <- harmon.RUVs(object)
object <- harmon.RUVr(object)
return(object)
}
cluster.all <- function(object){
object <- cluster.kmeans(object)
object <- cluster.hc(object)
object <- cluster.som(object)
object <- cluster.mnm(object)
object <- cluster.pam.euclidean(object)
object <- cluster.pam.pearson(object)
object <- cluster.pam.spearman(object)
return(object)
}
# Step 0: Prepare the 'precision' object
example_cluster <- create.precision.cluster(data = data.test, label = data.group)
# Step 1: Harmonize via all the methods
example_cluster <- harmon.all(example_cluster)
# Step 2: Clustering via all the methods
example_cluster <- cluster.all(example_cluster)
library(mclust)
# Step 2: Clustering via all the methods
example_cluster <- cluster.all(example_cluster)
example_cluster
# Step 4: Measure the consistency between the clustering labels and the true labels
cluster <- c('kmeans','hc','som','mnm', 'pam.euclidean','pam.pearson','pam.spearman')
harmon <- c('Raw','TC','UQ','med','TMM','DESeq','PoissonSeq','QN', 'RUVg','RUVs','RUVr')
ari_indexes <- data.frame(matrix(nrow=length(cluster),ncol=length(harmon)))
true_label <- as.factor(c(rep('MXF',150),rep('PMFH',150)))
ari_indexes <- data.frame(matrix(nrow=length(cluster),ncol=length(harmon)))
true_label <- as.factor(c(rep('MXF',27),rep('PMFH',27)))
for (i in 1:length(cluster)){
for (j in 1:length(harmon)){
eval(parse(text=paste0('est_cluster <-', 'analysis@cluster.result','$',cluster[i],'$',harmon[j])))
ari_indexes[i,j] <- mclust::adjustedRandIndex(true_label, est_cluster)
}
}
for (i in 1:length(cluster)){
for (j in 1:length(harmon)){
eval(parse(text=paste0('est_cluster <-', 'example_cluster@cluster.result','$',cluster[i],'$',harmon[j])))
ari_indexes[i,j] <- mclust::adjustedRandIndex(true_label, est_cluster)
}
}
ari_indexes
rownames(ari_indexes) <- cluster
?dist
?factoextra::get_dist
